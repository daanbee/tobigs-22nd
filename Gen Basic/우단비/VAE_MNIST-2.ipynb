{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1-1\n",
        "\n",
        "MNIST 데이터셋을 사용하여 간단한 VAE을 구현한 코드입니다.\n",
        "\n",
        "코드를 실행시키고, 주석을 달아주세요."
      ],
      "metadata": {
        "id": "MzG0kX5K68kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "KVnT38i07pPK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "batch_size = 100\n",
        "learning_rate = 0.0002\n",
        "img_size = 28 * 28\n",
        "latent_dim = 20\n",
        "hidden_size1 = 256\n",
        "hidden_size2 = 512\n",
        "hidden_size3 = 1024\n",
        "dir_name = \"VAE_results\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if not os.path.exists(dir_name):\n",
        "    os.makedirs(dir_name)\n",
        "\n",
        "transform = transforms.Compose([ # 이미지를 Tensor로 변환\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)) # 이미지를 정규화\n",
        "])"
      ],
      "metadata": {
        "id": "AbhamSuI7Eaa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터셋 로드\n",
        "MNIST_dataset = datasets.MNIST(root='../../data/',\n",
        "                               train=True,\n",
        "                               transform=transform,\n",
        "                               download=True)\n",
        "\n",
        "# DataLoader 설정\n",
        "data_loader = torch.utils.data.DataLoader(dataset=MNIST_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)"
      ],
      "metadata": {
        "id": "WIhwaLXY7PA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab17ddbc-a011-4713-d5ce-c62b163f7dee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 49902910.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1568688.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 2061823.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7375349.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module): # 인코더 클래스 정의 : 이미지를 저차원 잠재 공간으로 인코딩\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(img_size, hidden_size3)\n",
        "        self.fc2 = nn.Linear(hidden_size3, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size1)\n",
        "        self.fc_mean = nn.Linear(hidden_size1, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_size1, latent_dim)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x): # 인코더의 순전파 함수 정의\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        mean = self.fc_mean(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mean, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module): # 디코더 클래스 정의 : 잠재 공간에서 다시 이미지로 복원\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_size1)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "        self.fc4 = nn.Linear(hidden_size3, img_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x): # 디코더 순전파 함수 정의\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# 모델 생성 후 이동\n",
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)"
      ],
      "metadata": {
        "id": "-8ANJtF77Sv6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reparameterize(mean, logvar):\n",
        "    std = torch.exp(0.5 * logvar) # 표준편차 걔산\n",
        "    eps = torch.randn_like(std) # 표준 정규분포에서 무작위로 샘플링한 노이즈\n",
        "    return mean + eps * std # 잠재변수 z 수식\n",
        "\n",
        "# 손실함수 정의\n",
        "def loss_function(recon_x, x, mean, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum') # 재구성된 이미지와 실제 이미지 간의 차이\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp()) # 잠재 변수 분포와 정규 분포 간의 차이\n",
        "    return BCE + KLD\n",
        "\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate) # 인코더와 디코더의 파라미터들을 결합하여 Adam 옵티마이저 정의"
      ],
      "metadata": {
        "id": "TbFB4rGL7j6R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    encoder.train() # 인코더와 디코더를 학습 모드로 설정\n",
        "    decoder.train()\n",
        "    train_loss = 0 # 누적 손실 초기화\n",
        "\n",
        "    for images, _ in data_loader: # 이미지 불러오기\n",
        "        images = images.view(-1, img_size).to(device) # 1D 벡터로 변환하고 이동\n",
        "\n",
        "        images = (images + 1) / 2 # 정규화\n",
        "\n",
        "        optimizer.zero_grad() # 기울기 초기화\n",
        "\n",
        "        mean, logvar = encoder(images) # z의 평균과 분산 계산\n",
        "        z = reparameterize(mean, logvar) # z 샘플링\n",
        "        recon_images = decoder(z) # 디코더를 통해 잠재 변수 z로부터 이미지 복원\n",
        "\n",
        "        loss = loss_function(recon_images, images, mean, logvar) # 복원된 이미지와 원본 이미지 간 손실 계산\n",
        "        loss.backward() # 역전파를 통해 기울기 계산 및 가중치 업데이트\n",
        "        train_loss += loss.item() # 손실 값 누적\n",
        "        optimizer.step() # 가중치 업데이트\n",
        "\n",
        "    avg_loss = train_loss / len(data_loader.dataset) # 한 에포크 동안의 평균 손실 게산\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}') # 에포크마다 현재 손실 값 출력\n",
        "\n",
        "# 학습된 모델로 샘플 이미지 생성 및 저장\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        sample = decoder(z).view(-1, 1, 28, 28)\n",
        "        save_image(sample, os.path.join(dir_name, f'VAE_fake_image_{epoch + 1}.png'))"
      ],
      "metadata": {
        "id": "wJt3Iaj67nAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58971f4-7289-4e1e-a32f-f5c888fbed86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 200.7115\n",
            "Epoch [2/50], Loss: 148.1723\n",
            "Epoch [3/50], Loss: 129.8604\n",
            "Epoch [4/50], Loss: 123.2824\n",
            "Epoch [5/50], Loss: 118.6656\n",
            "Epoch [6/50], Loss: 115.1988\n",
            "Epoch [7/50], Loss: 112.7707\n",
            "Epoch [8/50], Loss: 111.0326\n",
            "Epoch [9/50], Loss: 109.5454\n",
            "Epoch [10/50], Loss: 108.2151\n",
            "Epoch [11/50], Loss: 107.0967\n",
            "Epoch [12/50], Loss: 106.1673\n",
            "Epoch [13/50], Loss: 105.3089\n",
            "Epoch [14/50], Loss: 104.5917\n",
            "Epoch [15/50], Loss: 103.9370\n",
            "Epoch [16/50], Loss: 103.3781\n",
            "Epoch [17/50], Loss: 102.8628\n",
            "Epoch [18/50], Loss: 102.3716\n",
            "Epoch [19/50], Loss: 101.9947\n",
            "Epoch [20/50], Loss: 101.5714\n",
            "Epoch [21/50], Loss: 101.2032\n",
            "Epoch [22/50], Loss: 100.8605\n",
            "Epoch [23/50], Loss: 100.5626\n",
            "Epoch [24/50], Loss: 100.2610\n",
            "Epoch [25/50], Loss: 99.9616\n",
            "Epoch [26/50], Loss: 99.7174\n",
            "Epoch [27/50], Loss: 99.4626\n",
            "Epoch [28/50], Loss: 99.2242\n",
            "Epoch [29/50], Loss: 99.0057\n",
            "Epoch [30/50], Loss: 98.7842\n",
            "Epoch [31/50], Loss: 98.5809\n",
            "Epoch [32/50], Loss: 98.3925\n",
            "Epoch [33/50], Loss: 98.1605\n",
            "Epoch [34/50], Loss: 97.9879\n",
            "Epoch [35/50], Loss: 97.8295\n",
            "Epoch [36/50], Loss: 97.6961\n",
            "Epoch [37/50], Loss: 97.5107\n",
            "Epoch [38/50], Loss: 97.3736\n",
            "Epoch [39/50], Loss: 97.1701\n",
            "Epoch [40/50], Loss: 97.0708\n",
            "Epoch [41/50], Loss: 96.9069\n",
            "Epoch [42/50], Loss: 96.7594\n",
            "Epoch [43/50], Loss: 96.6453\n",
            "Epoch [44/50], Loss: 96.5361\n",
            "Epoch [45/50], Loss: 96.4248\n",
            "Epoch [46/50], Loss: 96.2849\n",
            "Epoch [47/50], Loss: 96.1482\n",
            "Epoch [48/50], Loss: 96.0538\n",
            "Epoch [49/50], Loss: 95.9420\n",
            "Epoch [50/50], Loss: 95.8524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1-2\n",
        "\n",
        "아래 마크다운으로 VAE_fake_image_1.png와 VAE_fake_image_50.png를 함께 첨부해주세요.\n",
        "\n",
        "![VAE_fake_image_1](VAE_fake_image_1.png)\n",
        "![VAE_fake_image_50](VAE_fake_image_50.png)"
      ],
      "metadata": {
        "id": "GXpTKQSp8CBY"
      }
    }
  ]
}